> grok-code-fast

# Общая дорожная карта: Автономная OSS/airgapped WorkOS-like система на ZITADEL + Supabase + UI8Kit/Core

## Анализ стека и технологий

На основе анализа файлов [ZITADEL.md](ZITADEL.md) и [ZITADEL-OSS.md](ZITADEL-OSS.md), мы объединяем подходы в единый план. Цель — полностью автономная система для управления идентификацией и SSO, совместимая с airgapped средами (без внешних зависимостей во время работы).

### Ключевые компоненты стека
- **ZITADEL (self-hosted)**: Открытый Identity Provider (IdP) для OIDC/SSO. Управляет пользователями, организациями, проектами и приложениями. Развёртывается локально via Helm/Docker Compose. Поддерживает локальных пользователей и опциональные социальные провайдеры (Google, GitHub, Microsoft) с egress-allowlist.
- **Supabase (Postgres)**: Хранилище метаданных (тенанты, приложения, провайдеры, вебхуки, аудит, настройки). Локальный кластер Postgres, ограниченный VPC/сегментом. Используется для CRUD операций, без внешних API.
- **UI8Kit/Core**: Фреймворк для админ-портала и конструктора виджетов. Обеспечивает UI без внешних CDN/шрифтов — все ассеты локальные.
- **Микросервисы (Go)**: Бэкенд на Go для масштабируемости:
  - API Gateway: Аутентификация UI, маршрутизация.
  - Tenants/Apps/Providers Service: CRUD для тенантов/приложений/провайдеров (интеграция с Supabase).
  - ZITADEL Adapter: Управление org/project/app в ZITADEL via Management API (gRPC/REST).
  - Widget Builder/Assets: Генерация виджетов, темы, локальная доставка.
  - Webhooks Service: Обработка событий (login, user lifecycle), подпись, ретраи, dead-letter.
  - Audit Service: Журнал действий и событий.
- **Телеметрия**: SigNoz (self-hosted) с OpenTelemetry для traces/metrics/logs. Визуализация в админ-портале (UI8Kit/Core). Экспорт наружу отключён.
- **SDK/Quickstarts**: Для интеграции — Node/Next.js и Go. Включают верификацию JWT с локальным JWKS-кэшем.
- **Пакетирование**: Offline-бандлы образов, Docker Compose, Helm. SHA-манифесты для integrity.

### Преимущества стека для автономности
- **Airgapped-ready**: Нет внешних зависимостей (облако, CDN, API). Egress по умолчанию deny; allowlist для провайдеров.
- **Масштабируемость**: Микросервисы позволяют гибкое развёртывание (локально, k8s, облако).
- **Безопасность**: Локальные ассеты, прокси-совместимость (HTTP_PROXY, TLS CA bundles), оффлайн-JWT валидация.
- **GDPR/Compliance**: Поддержка локальных пользователей, аудит, шифрование (расширенные фичи не в MVP).
- **Интеграция**: OIDC для SSO, вебхуки для событий, виджеты для UI.

### Риски и ограничения
- Социальные провайдеры требуют egress — использовать allowlist или оффлайн-профиль.
- Требует инфраструктуру: k8s/Docker для развёртывания.
- Обновления via оффлайн-бандлы — нет авто-обновлений.

## Архитектура системы
- **IdP Layer**: ZITADEL self-host.
- **Data Layer**: Supabase Postgres (метаданные).
- **Service Layer**: Go-микросервисы.
- **UI Layer**: Admin Portal (React + UI8Kit), Demo Storefront.
- **Observability**: SigNoz + UI8Kit dashboards.
- **Integration**: SDKs, Webhooks, Widgets.

## Дорожная карта: Фазы, что, как, когда, на чём разворачивать

Roadmap ориентирован на автономность (OSS/airgapped). Временные рамки: 4 недели MVP. Развёртывание: Docker Compose для локалки, Helm для k8s/airgapped.

### Фаза 1: Self-host база и платформа-скелет (Неделя 1)
**Цель**: Базовая автономная инфраструктура без внешних зависимостей. Результат: E2E авторизация на демо, все ассеты локально.

**Что делать**:
- Поднять ZITADEL (self-host), Supabase (локальный Postgres).
- Разработать микросервисы: API Gateway, Tenants Service, ZITADEL Adapter.
- Создать Admin Portal: Онбординг тенанта, регистрация приложения, управление redirect URI.

**Как**:
- Использовать Docker Compose для локального развёртывания ZITADEL и Supabase.
- Настроить Management API ZITADEL для создания org/project/app.
- Интегрировать Supabase для хранения метаданных (таблицы: tenants, apps, providers).

**Когда**: Неделя 1.
**На чём разворачивать**:
- Локально: Docker Compose (файл docker-compose.yml с образами ZITADEL, Postgres).
- Airgapped: Offline-бандл образов (скачать заранее, загрузить в локальный registry).
- Требования: Docker, >=4GB RAM, Linux/Windows.

**Критерии успеха**: Создать тенанта → приложение → получить client_id/secret → OIDC авторизация работает на демо.

### Фаза 2: Виджеты и провайдеры (Неделя 2)
**Цель**: Конструктор виджетов и интеграция провайдеров. Результат: Подключение провайдера <10 мин, вход через виджет.

**Что делать**:
- Разработать Widget Builder: Конфиг, темы, i18n, JS-сниппет (zero-external deps).
- Создать мастера провайдеров: Google/GitHub/Microsoft с валидацией redirect URI, генерацией egress-allowlist.
- Интегрировать Demo Storefront с виджетом.

**Как**:
- Виджет: Генерировать локально, доставлять через микросервис.
- Провайдеры: UI для ввода credentials, проверка конфигов via ZITADEL API.
- Для airgapped: Оффлайн-профиль без провайдеров.

**Когда**: Неделя 2.
**На чём разворачивать**:
- Продолжение Docker Compose. Для airgapped: Helm чарты с локальными образами.
- Тестирование: Локально с mock-провайдерами.

**Критерии успеха**: Админ подключает провайдера и логинится через виджет на демо.

### Фаза 3: SDK, вебхуки и телеметрия (Неделя 3)
**Цель**: Интеграционные инструменты и наблюдаемость. Результат: SDK работают оффлайн, вебхуки устойчивы, телеметрия без внешних сервисов.

**Что делать**:
- Разработать SDKs: Node/Next.js, Go с локальным JWKS-кэшем.
- Реализовать Webhooks Service: Подпись, ретраи, dead-letter.
- Настроить SigNoz (self-host) + OpenTelemetry; дашборды в Admin Portal (UI8Kit).

**Как**:
- SDK: Включить кэширование JWKS для оффлайн-валидации JWT.
- Webhooks: Использовать Supabase для подписок, ZITADEL для событий.
- Телеметрия: Сбор traces от сервисов в SigNoz; агрегация в UI8Kit.

**Когда**: Неделя 3.
**На чём разворачивать**:
- Docker Compose с добавлением SigNoz образа.
- Airgapped: Локальный registry, Helm для k8s.

**Критерии успеха**: Backend получает вебхук о входе; SDK проходят e2e; телеметрия собирается локально.

### Фаза 4: Airgapped пакетирование и эксплуатация (Неделя 4)
**Цель**: Полная автономность и готовность к продакшену. Результат: Установка в изолированной сети <30 мин, совместимость с прокси.

**Что делать**:
- Создать offline-бандлы: Образы, Helm/Compose, SHA-манифесты.
- Настроить профили сети: Default-deny egress, allowlist генератор, полный оффлайн.
- Добавить CLI для управления; чек-листы, тест-матрица прокси (Squid/Nginx).

**Как**:
- Пакетирование: Собрать все образы в tar.gz с контрольными суммами.
- Прокси-совместимость: Поддержка HTTP_PROXY, кастомный CA, gRPC fallback.
- Документация: Гайды по развёртыванию, эксплуатации.

**Когда**: Неделя 4.
**На чём разворачивать**:
- Airgapped: Локальный k8s (K3s) или Docker. Загрузка бандла в изолированную сеть.
- Продакшен: Helm на managed k8s (без egress).

**Критерии успеха**: Развёртывание <30 мин без интернета; тесты прокси проходят; интеграция по гайду без поддержки.

### Общие acceptance-критерии MVP
- Онбординг: От установки до SSO <30 мин, без интернета.
- Виджет: Вставляется сниппетом, локальные темы.
- Провайдеры: 3+ доступны (с egress), оффлайн работает.
- SDK: Запускаются одной командой, JWT валидация оффлайн.
- Телеметрия: Сбор в SigNoz, дашборды в портале.
- Совместимость: Прокси, TLS, airgapped.

### Следующие шаги после MVP
- Тестирование с реальными пользователями.
- Добавление advanced фич (GDPR шифрование, multi-region).
- Мониторинг и поддержка.

Этот roadmap обеспечивает автономную систему, готовую к airgapped средам. Если нужно доработать или начать реализацию, дай знать!
